\chapter*{Results}
\label{ch:results}
% The performances of the models were evaluated using the
% \texttt{classification\_report} function from the \texttt{scikit-learn} library. 
% This function is particularly useful as it offers an overview of key evaluation
% metrics commonly used in Machine Learning, i.e. accuracy, precision, recall,
% and F1-score.\\
The performance metrics taken into account for evaluation are the following:
accuracy, precision, recall, and F1-score. Taking all of them into account
is crucial to accurately evaluate how well each model performs.

For the static models implemented in this project, the classification report
revealed an accuracy of 34\% for the Random Forest algorithm and 43\% for SVM. 
These results can be considered reasonable, given that the task at hand is a
multi-class classification problem with 8 classes.\\

Neural Networks' performances were generally not on par with the ones obtained by
the static models.
As mentioned in the previous chapter, the development of neural networks
iterated testing phases and adjustments over different configurations for data
splitting, preprocessing, architectures and training parameters were tested.
Downsampling the set into evenly represented classes, and splitting evenly
improves the models' performances slightly.
Because of the generally poor results, semi-supervised learning did not get
important results.
Judging from the confusion matrix % TODO quote graphs
and training and validation accuracy plots, the models tend to confuse the classes.
This might be because of heavy high frequency overlapping terms between the classes


\textbf{AGGIUNGERE ALTRO}