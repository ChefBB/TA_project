\chapter*{Results}
\label{ch:results}
The performance metrics considered for evaluation in these analysis are the
following: accuracy, precision, recall, and F1-score. Considering all of these
metrics is crucial to accurately evaluate how well each model performs.
The classification
report revealed an accuracy of 34\% for Random Forest.
This result can be considered reasonable, given the fact that the task at hand
is a multi-class classification problem with 8 classes.\\

For the Random Forest model, the class with the highest F1-score is \textit{anger}, at 51\%,
which is the third class as for support, sitting at 4436. 
\textit{Joy} was the most supported class, with 5854 instances, but it came second
as for the F1-score, which was of 0.40. The second class based off support, which
was \textit{fear} with 4652 instances, had a lower F1-score of 0.31. 
The remaining classes showed comparable support and F1-scores, averaging around
3500 instances and 0.25 respectively, only \textit{disgust} had a considerably
lower F1-score, at 18\%. \\
In image \ref{fig:cm_rf}, the confusion matrix of Random Forest is displayed.
It is clear how the best classified classes are
\textit{joy} and \textit{anger}. However, the most interesting insight that can
be gathered from the confusion matrix is the extent to which all other classes
get misclassified as \textit{joy}. This is probably because \textit{joy} is the
dominant class, due to an imbalanced dataset.
Furthermore, as was highlighted in previous sections, the most important
features for classification are significantly shared between the classes,
therefore making it harder for the model to classify correctly.
Then, image \ref{fig:cwa_rf} shows class-wise accuracy.\\
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pictures/class_accuracy_rf.png}
        \caption{Class-wise Accuracy - Random Forest}
        \label{fig:cwa_rf}
    \end{subfigure}
    \begin{subfigure}{0.55\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pictures/confusion_matrix_rf.png}
        \caption{Confusion Matrix for the Random Forest Classifier}
        \label{fig:roc_rf}
    \end{subfigure}
    \caption{Random Forest - plots}
    \label{fig:side_by_side}
\end{figure}

% For the Random Forest model, the class with the highest F1-score is \texttt{anger},
% which is the third class as for support, sitting at 4436. 
% \texttt{Joy} was the most supported class, with 5854 instances, but it came second
% as for the F1-score, which was of 0.40. The second class based off support, which
% was \texttt{fear} with 4652 instances, had a lower F1-score of 0.31. 
% The remaining classes showed comparable support and F1-scores, averaging around
% 3500 instances and 0.25 respectively, only \texttt{disgust} had a considerably
% lower F1-score, at 18\%. In image \ref{fig:roc_rf}, the ratio of true positives versus false positives is
% displayed, with the Random Forest classifier scoring lower than a random guesser in
% two out of eight classes. Image \ref{fig:cwa_rf} shows class-wise accuracy.\\
% \begin{figure}[H]
%     \centering
%     \begin{subfigure}{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{pictures/roc_rf.png}
%         \caption{ROC Curve for the Random Forest Classifier}
%         \label{fig:roc_rf}
%     \end{subfigure}
%     \begin{subfigure}{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{pictures/class_accuracy.png}
%         \caption{Class-wise Accuracy - Random Forest}
%         \label{fig:cwa_rf}
%     \end{subfigure}
%     \caption{Random Forest - plots}
%     \label{fig:side_by_side}
% \end{figure}

%\begin{figure}[H]
 %   \centering
  %  \includegraphics[width=0.5\linewidth]{pictures/roc_rf.png}
   % \caption{ROC Curve for the Random Forest Classifier}
   % \label{fig:roc_rf}
%\end{figure}

%\begin{figure}[H]
 %   \centering
  %  \includegraphics[width=0.5\linewidth]{pictures/class_accuracy.png}
  %  \caption{Class-wise Accuracy - Random Forest}
  %  \label{fig:cwa_rf}
%\end{figure}

% For the Support Vector Machine model, the class with the highest F1-score is \texttt{fear}, followed by \texttt{anger} at 0.31 and \texttt{anticipation} at 0.25. 
% As for the other classes, the scores were not as comparable as for Random Forest, oscillating between the 22\% of \texttt{sadness} and the 7\% of \texttt{joy}, with \texttt{disgust} and \texttt{trust} sitting at 16\%, and \texttt{surprise} at 12\%. 
% Surprisingly, \texttt{joy} is the least performing class for SVC, dispite having the highest support.   
% In image \ref{fig:roc_svm}, the ratio of true positives versus false positives is displayed. 
% The SVM model performs better than a random guesser in all of the classes, therefore surpassing Random Forest despite the lower scores of accuracy. 
% Lastly, image \ref{fig:cwa_svm} shows the class-wise accuracy by SVM, highlighting a clear and strong disparity in the classification performances among the classes.
% \begin{figure}[H]
%     \centering
%     \begin{subfigure}{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{pictures/roc_svc.png}
%         \caption{ROC Curve - SVM}
%         \label{fig:roc_svm}
%     \end{subfigure}
%     \begin{subfigure}{0.53\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{pictures/class_accuracy_SVC.png}
%         \caption{Class-wise Accuracy - SVM}
%         \label{fig:cwa_svm}
%     \end{subfigure}
%     \caption{SVM - plots}
%     \label{fig:svm_metrics}
% \end{figure}

%\begin{figure}[H]
 %   \centering
%    \includegraphics[width=0.5\linewidth]{pictures/roc_svc.png}
 %   \caption{ROC Curve - SVM}
  %  \label{fig:roc_svm}
%\end{figure}
%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.5\linewidth]{pictures/class_accuracy_SVC.png}
%    \caption{Class-wise Accuracy - SVM}
%    \label{fig:cwa_svm}
%\end{figure}

As mentioned in the previous chapter, the development of neural networks
iterated testing phases and adjustments over different aspects of training.
Semi-supervised learning through generation of pseudo labels via the partially
trained models generally yielded poor results; on the other hand, downsampling
into evenly represented labels gave some minor improvements, for both architectures.
The neural networks generally underperformed compared to Random Forest:
the convolutional neural network ultimately reached a test categorical accuracy
of 0.2128, while the recurrent neural network had a test accuracy of 0.1869.\\

The graphs below show various performance metrics of the network with the better
performances for the convolutional architecture.
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \includegraphics[width=\textwidth]{pictures/cnn_accuracy.png}
        \caption{Training and validation accuracy}
        \label{fig:cnn_train_val_acc}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pictures/cnn_class_accuracy.png}
        \caption{Class-wise accuracy}
        \label{fig:cnn_classacc}
    \end{subfigure}
    \begin{subfigure}{0.6\textwidth}
        \includegraphics[width=\textwidth]{pictures/cnn_confusion_matrix.png}
        \caption{Confusion matrix}
        \label{fig:cnn_confmatr}
    \end{subfigure}
    % \begin{subfigure}{0.45\textwidth}
    %     \includegraphics[width=\textwidth]{pictures/cnn_roc_curve.png}
    %     \caption{Roc curve}
    %     \label{fig:cnn_roccurve}
    % \end{subfigure}
    \caption{Convolutional Neural Network - plots}
    \label{fig:cnn_performances}
\end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\linewidth]{pictures/cnn_class_accuracy.png}
%     \caption{Convolutional Neural Network's class-wide accuracy}
%     \label{fig:cnn_classacc}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\linewidth]{pictures/cnn_confusion_matrix.png}
%     \caption{Convolutional Neural Network's confusion matrix}
%     \label{fig:cnn_confmatr}
% \end{figure}

The graphs below show various performance metrics of the network with the better
performances for the recurrent architecture.
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \includegraphics[width=\textwidth]{pictures/rnn_accuracy.png}
        \caption{Training and validation accuracy}
        \label{fig:rnn_train_val_acc}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{pictures/rnn_class_accuracy.png}
        \caption{Class-wise accuracy}
        \label{fig:rnn_classacc}
    \end{subfigure}
    \begin{subfigure}{0.6\textwidth}
        \includegraphics[width=\textwidth]{pictures/rnn_confusion_matrix.png}
        \caption{Confusion matrix}
        \label{fig:rnn_confmatr}
    \end{subfigure}
    % \begin{subfigure}{0.45\textwidth}
    %     \includegraphics[width=\textwidth]{pictures/rnn_roc_curve.png}
    %     \caption{Roc curve}
    %     \label{fig:rnn_roccurve}
    % \end{subfigure}
    \caption{Recurrent Neural Network - plots}
    \label{fig:rnn_performances}
\end{figure}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.40\linewidth]{pictures/rnn_accuracy.png}
%     \caption{Convolutional Neural Network's training and validation accuracy}
%     \label{fig:rnn_train_val_acc}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\linewidth]{pictures/rnn_class_accuracy.png}
%     \caption{Convolutional Neural Network's class-wide accuracy}
%     \label{fig:rnn_classacc}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\linewidth]{pictures/rnn_confusion_matrix.png}
%     \caption{Convolutional Neural Network's confusion matrix}
%     \label{fig:rnn_confmatr}
% \end{figure}
% TODO

% Judging from the confusion matrices
% and training and validation accuracy plots, the models tend to confuse the classes.
% This might be because of heavy high frequency overlapping terms between the classes