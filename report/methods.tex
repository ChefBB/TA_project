\chapter*{Methods}
\label{ch:capitolo2}

% This section will provide an overview about the data, methods and procedures used in the project.\\

The dataset used in this project is a sampled subset of English-language
songs derived from the \textit{Genius Song Lyrics Dataset}\textsuperscript{\cite{geniusdataset}}.
% The original dataset (3m records) included songs in many different languages;
% however, this work focused exclusively on English-language ones.
The original dataset contained numerous attributes; the ones considered
relevant for model training are:
\begin{itemize}
    \item \textbf{title:} the song's title;
    % \item \textbf{artist:} the artist
    % \item \textbf{year:}
    % \item \textbf{views:}
    % \item \textbf{features:}

    % \item \textbf{id:}
    \item \textbf{lemmatized\_stanzas:} lyrics of the single stanza;
    
    \item \textbf{stanza\_number:} identifies the position of the stanza in the song;

    \item \textbf{is\_chorus:} boolean variable that attests whether the stanza is
        a chorus or not;
    
    \item \textbf{tag:} represents the genre of the song. For easier handling,
        this attribute of the original dataset has been one-hot encoded into various boolean variables
        (is\_country, is\_pop, is\_rap, is\_rb, is\_rock);

    \item \textbf{label:} represents the emotional classification of the stanza,
        assigned by Albert Base v2\textsuperscript{\cite{albert-base-v2}} model.
    
    % \item \textbf{is\_country:}
    % \item \textbf{is\_pop:}
    % \item \textbf{is\_rap:}
    % \item \textbf{is\_rb:}
    % \item \textbf{is\_rock:}
\end{itemize}

% The dataset originally didn't contain emotion labels, essential for training the models.
% To create the ground truth, the model
% Albert Base v2\textsuperscript{\cite{albert-base-v2}} was used, classifying
% stanzas' lyrics into Plutchik's eight primary emotions.
All of these attributes, except for \texttt{title}, were the result
of the preprocessing phase, as described in section~\ref{preprocessing}.
Due to limited computational power, the labeling process was time-intensive,
ultimately resulting in a limited dataset consisting of
\textbf{(QUANTE? AGGIUNGEREI NUMERO STROFE)}.


\section*{Preprocessing}
\label{preprocessing}
The initial preprocessing step involved sampling from the original dataset
while maintaining the proportional distribution of genres.
This approach ensured that the genre representation in the sampled subset
accurately reflected that of the full dataset.\\

% The preliminary text cleaning process focused on the \texttt{lyrics} attribute,
% which was the attribute of the original dataset that contained
% the entire lyrics of each song (in string format). Initially, we built a RegEx
% to clean the lyrics' strings from noise, specifically targeting words enclosed
% between square brackets that were irrelevant for the stanza splitting process.
% Many of the keywords marking different stanzas were written within square brackets,
% and removing the non-keyword items within brackets was essential to prevent
% potential issues. \\
% The crucial step was the stanza splitting. After cleaning the strings from the
% noisy square-bracketed items, we split them based on various keywords used to
% denote stanzas (such as \texttt{chorus, verse, intro, outro, refrain, hook} etc.). 
% The RegEx we developed also accounted for the different formats in which these
% keywords appeared; between square brackets, parentheses, without brackets, only a
% double newline character between one stanza and the other.
% The output of this step was, for each song record, a list of stings, corresponding
% to a list of stanzas (with the stanza's header as the corresponding keyword). \\
% Next, we removed the resulting strings that were uninformative; such as empty
% strings or those with fewer than 20 characters, which were too short to provide
% useful content. \\
% As a result, the output of this preliminary preprocessing phase is a dataset in
% which the records are not whole songs anymore but single stanzas; each numbered
% based on its position in the song. \\

The preliminary text cleaning process focused on the \texttt{lyrics} attribute,
which contained the complete lyrics of each song in string format.
Initially, a regular expression (RegEx) was built to remove noise from the
lyrics, specifically targeting words enclosed in square brackets that were
irrelevant to the stanza splitting process. Many keywords marking different
stanzas were written within square brackets, and removing non-keyword items
inside brackets was crucial to avoid potential issues.\\

The next critical step was stanza splitting. After cleaning texts from
noisy square-bracketed items, lyrics were split based on various keywords
used to denote stanzas (such as "chorus", "verse", "intro", "outro", "refrain", "hook", etc.).
The RegEx developed accounted for the different formats in which these keywords
appeared, including square brackets, parentheses, or no brackets at all, as well
as stanzas separated only by double newline characters.
The output of this step was, for each song record, a list of strings
representing individual stanzas (each stanza has also a header with the corresponding
keyword; this aspect will be discussed in the next paragraph).
Next, uninformative strings—such as empty strings or those with fewer
than 20 characters—were removed, as they were too short to provide meaningful
content.
As a result, the output of this preliminary preprocessing phase was a dataset
where the records were no longer whole songs but individual stanzas, each
numbered according to its position within the song.\\

% A further and deeper cleaning process on the stanzas involved the creation of the
% boolean feature \texttt{is\_chorus}; \texttt{true} value for repeated stanzas for
% the same song or stanzas that had \texttt{hook, chorus, refrain, bridge} as a
% header. \\
% We then removed the stanza headers and the newline characters between verses to
% obtain cleaner stanzas. \\ 
% Since choruses, hooks, bridges and refrains often repeat throughout songs, we
% decided to drop duplicate stanzas in order to avoid redundant data.
% This resulted in a dataset of cleaned and non-duplicate stanzas: the checkpoint
% for the labelling step and the starting point for the text lemmatization process.
% To label the dataset, the Albert Base v2 model has been used; this transformer
% model is primarily aimed at being fine-tuned on tasks that use the whole sentence
% to make decisions, such as sequence classification. 
% \\
% The next step involved lemmatizing stanzas using the \texttt{spaCy} library. We
% created a list of lemmatized tokens (filtering punctuation and empty words). 
% We opted for lemmatization over stemming because lemmatization produces more
% accurate and meaningful results, particularly for tasks requiring semantic
% understanding, such as in our case.


A further and more detailed cleaning process on the stanzas involved the creation
of the boolean feature \texttt{is\_chorus}, which was assigned a \texttt{true}
value for repeated stanzas within the same song or for stanzas with headers such
as "hook", "chorus", "refrain", or "bridge".
Next, stanza headers and newline characters between verses were removed to obtain
cleaner stanzas.
Since choruses, hooks, bridges, and refrains often repeat throughout songs,
duplicate stanzas were discarded to avoid redundant data. This resulted in a
dataset of cleaned, non-duplicate stanzas, which served as the checkpoint for
the labeling step and the starting point for the text lemmatization process.\\

The subsequent step involved lemmatizing the stanzas using the \texttt{spaCy}
library. A list of lemmatized tokens was created by filtering out punctuation
and empty words. Lemmatization was chosen over stemming because it produces
more accurate and meaningful results, particularly for tasks requiring semantic
understanding, such as the one at hand.\\

Since the dataset was not pre-labeled at the stanza level, ALBERT Base v2 was employed for this task.
This transformer model is specifically designed to be fine-tuned on tasks that
require an understanding of the entire sentence, such as sequence classification.\\


\section{Models developement}
\section{Evaluation}

