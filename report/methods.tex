\chapter*{Methods}
\label{ch:capitolo2}

% This section will provide an overview about the data, methods and procedures used in the project.\\

The dataset used in this project is a sampled subset of English-language
songs derived from the \textit{Genius Song Lyrics Dataset}\textsuperscript{\cite{geniusdataset}}.
% The original dataset (3m records) included songs in many different languages;
% however, this work focused exclusively on English-language ones.
The original dataset contained numerous attributes; the ones considered
relevant for model training are:
\begin{itemize}
    \item \textbf{title:} the song's title;
    % \item \textbf{artist:} the artist
    % \item \textbf{year:}
    % \item \textbf{views:}
    % \item \textbf{features:}

    % \item \textbf{id:}
    \item \textbf{lemmatized\_stanzas:} lyrics of the single stanza;
    
    \item \textbf{stanza\_number:} identifies the position of the stanza in the song;

    \item \textbf{is\_chorus:} boolean variable that attests whether the stanza is
        a chorus or not;
    
    \item \textbf{tag:} represents the genre of the song. For easier handling,
        this attribute of the original dataset has been one-hot encoded into various boolean variables
        (is\_country, is\_pop, is\_rap, is\_rb, is\_rock);

    \item \textbf{label:} represents the emotional classification of the stanza,
        assigned by Albert Base v2\textsuperscript{\cite{albert-base-v2}} model.
    
    % \item \textbf{is\_country:}
    % \item \textbf{is\_pop:}
    % \item \textbf{is\_rap:}
    % \item \textbf{is\_rb:}
    % \item \textbf{is\_rock:}
\end{itemize}

% The dataset originally didn't contain emotion labels, essential for training the models.
% To create the ground truth, the model
% Albert Base v2\textsuperscript{\cite{albert-base-v2}} was used, classifying
% stanzas' lyrics into Plutchik's eight primary emotions.
All of these attributes, except for \texttt{title}, were the result
of the preprocessing phase, as described in section~\ref{preprocessing}.
Due to limited computational power, the labeling process was time-intensive,
ultimately resulting in a limited dataset consisting of
\textbf{(QUANTE? AGGIUNGEREI NUMERO STROFE)}.


\section*{Preprocessing}
\label{preprocessing}
The initial preprocessing step involved sampling from the original dataset
while maintaining the proportional distribution of genres.
This approach ensured that the genre representation in the sampled subset
accurately reflected that of the full dataset.\\

% The preliminary text cleaning process focused on the \texttt{lyrics} attribute,
% which was the attribute of the original dataset that contained
% the entire lyrics of each song (in string format). Initially, we built a RegEx
% to clean the lyrics' strings from noise, specifically targeting words enclosed
% between square brackets that were irrelevant for the stanza splitting process.
% Many of the keywords marking different stanzas were written within square brackets,
% and removing the non-keyword items within brackets was essential to prevent
% potential issues. \\
% The crucial step was the stanza splitting. After cleaning the strings from the
% noisy square-bracketed items, we split them based on various keywords used to
% denote stanzas (such as \texttt{chorus, verse, intro, outro, refrain, hook} etc.). 
% The RegEx we developed also accounted for the different formats in which these
% keywords appeared; between square brackets, parentheses, without brackets, only a
% double newline character between one stanza and the other.
% The output of this step was, for each song record, a list of stings, corresponding
% to a list of stanzas (with the stanza's header as the corresponding keyword). \\
% Next, we removed the resulting strings that were uninformative; such as empty
% strings or those with fewer than 20 characters, which were too short to provide
% useful content. \\
% As a result, the output of this preliminary preprocessing phase is a dataset in
% which the records are not whole songs anymore but single stanzas; each numbered
% based on its position in the song. \\

The preliminary text cleaning process focused on \texttt{lyrics},
which contained the complete lyrics of each song in string format.
Initially, a regular expression (RegEx) was built to remove noise from the
lyrics, specifically targeting words enclosed in square brackets that were
irrelevant to the stanza splitting process. Many keywords marking different
stanzas were written within square brackets, and removing non-keyword items
inside brackets was crucial to avoid potential issues.\\

The next critical step was stanza splitting. After cleaning texts from
noisy square-bracketed items, lyrics were split based on various keywords
used to denote stanzas (such as "chorus", "verse", "intro", "outro", "refrain", "hook", etc.).
The RegEx developed accounted for the different formats in which these keywords
appeared, including square brackets, parentheses, or no brackets at all, as well
as stanzas separated only by double newline characters.
The output of this step was, for each song record, a list of strings
representing individual stanzas (each stanza has also a header with the corresponding
keyword; this aspect will be discussed in the next paragraph).
Next, uninformative strings—such as empty strings or those with fewer
than 20 characters—were removed, as they were too short to provide meaningful
content.
As a result, the output of this preliminary preprocessing phase was a dataset
where the records were no longer whole songs but individual stanzas, each
numbered according to its position within the song.\\

% A further and deeper cleaning process on the stanzas involved the creation of the
% boolean feature \texttt{is\_chorus}; \texttt{true} value for repeated stanzas for
% the same song or stanzas that had \texttt{hook, chorus, refrain, bridge} as a
% header. \\
% We then removed the stanza headers and the newline characters between verses to
% obtain cleaner stanzas. \\ 
% Since choruses, hooks, bridges and refrains often repeat throughout songs, we
% decided to drop duplicate stanzas in order to avoid redundant data.
% This resulted in a dataset of cleaned and non-duplicate stanzas: the checkpoint
% for the labelling step and the starting point for the text lemmatization process.
% To label the dataset, the Albert Base v2 model has been used; this transformer
% model is primarily aimed at being fine-tuned on tasks that use the whole sentence
% to make decisions, such as sequence classification. 
% \\
% The next step involved lemmatizing stanzas using the \texttt{spaCy} library. We
% created a list of lemmatized tokens (filtering punctuation and empty words). 
% We opted for lemmatization over stemming because lemmatization produces more
% accurate and meaningful results, particularly for tasks requiring semantic
% understanding, such as in our case.


A further and more detailed cleaning process on the stanzas involved the creation
of the boolean feature \texttt{is\_chorus}, which was assigned \texttt{true}
for repeated stanzas within the same song or for stanzas with headers such
as "hook", "chorus", "refrain", or "bridge".
Next, stanza headers and newline characters between verses were removed to obtain
cleaner stanzas.
Since choruses, hooks, bridges, and refrains often repeat throughout songs,
duplicate stanzas were discarded to avoid redundant data. This resulted in a
dataset of cleaned, non-duplicate stanzas, which served as the checkpoint for
the labeling step and the starting point for the text lemmatization process.\\

The subsequent step involved lemmatizing the stanzas using the
\texttt{spaCy}\textsuperscript{\cite{spacy}}
library. A list of lemmatized tokens was created by filtering out punctuation
and empty words. Lemmatization was chosen over stemming because it produces
more accurate and meaningful results, particularly for tasks requiring semantic
understanding, such as the one at hand.\\

Since the dataset was not pre-labeled at the stanza level, ALBERT Base v2 was employed for this task.
This transformer model is specifically designed to be fine-tuned on tasks that
require an understanding of the entire sentence, such as sequence classification.


\section*{Static Models}
The development of static models was straight forward, emphasizing simplicity.
Static models were mainly developed to provide a performance comparison
for the more complex Neural Networks.
The two models share the same architectural framework: a preprocessing
layer to handle the inputs, followed by a classifier for prediction.\\

The preprocessing layer processes both \texttt{title} and
\texttt{lemmatized\_stanzas} through
Term Frequency-Inverse Document Frequency, % TODO: why tf-idf???
to quantify term-wise importance
within the dataset. The boolean attributes
are converted to integers for compatibility with the model,
while \texttt{stanza\_number} is scaled
to ensure uniformity and prevent bias due to its magnitude.\\

To optimize model performance, hyperparameter space exploration was conducted
using Random Search.
Cross-validation is also used in order to provide a more accurate
estimate of model performance, ensuring that the results are less influenced
by dataset splits. Additionally, cross-validation helps prevent overfitting,
especially in cases of limited data availability or class imbalance. 



\section*{Neural Networks}
The Neural Network models can be trained with the \texttt{neural\_networks.py}
script. This script offers the possibility of configuring various parameters for
training, which was used to test different configurations:
\begin{itemize}
    \item \textbf{\texttt{type}}: specifies which type of Neural
    Network is to be trained. \texttt{1} is default, indicating
    One-Dimensional Convolutional Neural Networks training.
    Setting it to \texttt{2} trains a Recurrent Neural Network.

    \item \textbf{\texttt{epochs}}: Defines the number of epochs for training,
    allowing control over the duration of the learning process.

    \item \textbf{\texttt{semisupervised}}: Specifies the number of epochs
    dedicated to semi-supervised learning. If this parameter is omitted,
    the model is trained using only labeled data.

    \item \textbf{\texttt{reset}}: When included, the model is reset before
    starting training on newly pseudo-labeled data. This approach repurposes
    semi-supervised learning as a form of data augmentation rather than as
    transfer learning, providing an opportunity to enhance performance with
    pseudo-labeled examples.
    
    \item \textbf{\texttt{even-labels}}: When included, ensures even class
    representation in the dataset by downsampling overrepresented classes.
\end{itemize}

The architectures were developed and tuned through empirical,
reiterated testing. These parameters helped with the process, and can
be used for further experimentation.

% Both the Recurrent and One-Dimensional Convolutional Neural Network
% have the same non recurrent architecture. Except for\texttt{lemmatized\_stanzas}
% and \texttt{title},
% other attributes are preprocessed as in Static Models' preprocessing.\\

Both the Recurrent Neural Network and the One-Dimensional Convolutional
Neural Network share the same preprocessing
architecture. Most attributes are processed in the same manner as in
the Static Models; specific steps are applied to \texttt{lemmatized\_stanzas}
and \texttt{title}.
Non-Negative Matrix Factorization is applied to \texttt{title} in addition to
Term Frequency-Inverse Document Frequency
to extract latent topics, providing a richer representation of the
textual data.\\

\texttt{lemmatized\_stanzas} are handled by Convolutional and Recurrent
pipelines of the two Networks.
Elements are first tokenized, and then padded in order to
get an input with consistent shape, which is essential for both types of
recurrent layers.\\

\subsection*{One-Dimensional Convolutional Neural Network}
% The Convolutional part of the network uses three convolutional
% layers, followed by a 1-Dimensional Global Max Pooling layer, to reduce
% dimensionality. This convolutional pipeline is then concatenated with the
% other pipelines.

The Convolutional part of the architecture is designed to extract and learn
local patterns in \texttt{embedding\_lyrics}.
Its structure consists of three convolutional layers, each applying filters of
varying sizes. This allows to detect patterns at different granularities.
These layers are followed by Global Max Pooling, to reduce the previous output's
dimension to a fixed-length vector, as well as retaining focus on the most
informative patterns.
A dropout layer is then applied, to introduce regularization and prevent
overfitting.


\subsection*{Recurrent Neural Network}
The Recurrent part of the architecture is designed to extract and learn
local patterns in \texttt{embedding\_lyrics}.
Its structure consists of three gated recurrent units (\texttt{GRU})
to model temporal relationships. These are progressively formed by smaller
numbers of units, in order to capture patterns. All three layers in the
architecture use the \texttt{tanh} activation function to compute the hidden state and
the \texttt{sigmoid} activation function for the recurrent gate.
The first and second layers return the full sequence of hidden states for each
time step in the input sequence, enabling richer learning of patterns over time.
Dropout is applied on every layer, to prevent overfitting and add regularization.


\subsection*{Shared Components}
% The two pipelines described above are concatenated with a simple pipeline,
% which handles remaining features.
The remaining features are handled by a simple pipeline, which concatenates
their Input layers.
The inputs are passed them through a dense layer to create a compact
representation.
% Additional Features Input:
% stanza\_number\_input (numeric input for stanza number, scaled).
% Boolean Inputs: Flags for specific categories are processed as integer inputs.
% Topic Modeling Input: Outputs from Non-Negative Matrix Factorization (NMF)
% representing the title's topics.
% Dense Layer for Additional Inputs:
% The additional inputs are concatenated and passed through a Dense layer with
% 32 units and ReLU activation to create a compact representation.
% Combining Textual and Additional Features:
The output of the lyrics-processing branch is concatenated with the processed
additional features.
% Dense Layers for Classification:
The combined representation is passed through a Dense layer with 32 units
(ReLU activation), followed by a Dropout layer with a rate of 0.3.
Finally, the output layer uses 8 units with a softmax activation, corresponding
to the classification into 8 emotion categories.


\section*{Evaluation}
