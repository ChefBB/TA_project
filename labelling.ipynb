{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-21 10:10:13.981824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       text       emotion\n",
      "0         I am so excited about the future!  anticipation\n",
      "1  This is such a disappointing experience.       disgust\n",
      "2  I'm terrified of what might happen next.          fear\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the BART large MNLI model for zero-shot classification\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define possible emotion labels\n",
    "emotion_labels = [\n",
    "    \"anger\", \"anticipation\", \"joy\", \"trust\",\n",
    "    \"fear\", \"surprise\", \"sadness\", \"disgust\"\n",
    "]\n",
    "\n",
    "\n",
    "# Example dataframe\n",
    "data = {'text': [\n",
    "    \"I am so excited about the future!\",\n",
    "    \"This is such a disappointing experience.\",\n",
    "    \"I'm terrified of what might happen next.\",\n",
    "]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to classify emotions\n",
    "def classify_emotion(text, labels):\n",
    "    result = classifier(text, candidate_labels=labels)\n",
    "    return result['labels'][0]  # Return the top label\n",
    "\n",
    "# Apply the classification to each row in the dataframe\n",
    "df['emotion'] = df['text'].apply(lambda x: classify_emotion(x, emotion_labels))\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
