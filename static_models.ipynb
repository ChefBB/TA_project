{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = '/Users/brunobarbieri/Library/CloudStorage/OneDrive-UniversityofPisa/TA_Project/data/'\n",
    "df = pd.read_csv(path + \"lab_lem_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>is_country</th>\n",
       "      <th>is_pop</th>\n",
       "      <th>is_rap</th>\n",
       "      <th>is_rb</th>\n",
       "      <th>is_rock</th>\n",
       "      <th>stanza_number</th>\n",
       "      <th>is_chorus</th>\n",
       "      <th>lemmatized_stanzas</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Something in the Water</td>\n",
       "      <td>Pokey LaFarge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10902</td>\n",
       "      <td>{''}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[she, get, a, broke, down, el, camino, in, the...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Something in the Water</td>\n",
       "      <td>Pokey LaFarge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10902</td>\n",
       "      <td>{''}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[something, in, the, water, something, in, the...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Something in the Water</td>\n",
       "      <td>Pokey LaFarge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10902</td>\n",
       "      <td>{''}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>[she, do, her, makeup, and, hair, to, cook, fr...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Something in the Water</td>\n",
       "      <td>Pokey LaFarge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10902</td>\n",
       "      <td>{''}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>[my, hoosi, girl, be, so, fine, shake, the, wa...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Something in the Water</td>\n",
       "      <td>Pokey LaFarge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10902</td>\n",
       "      <td>{''}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[something, in, the, water, something, in, the...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66910</th>\n",
       "      <td>66910</td>\n",
       "      <td>15437</td>\n",
       "      <td>PRETTY</td>\n",
       "      <td>Kennie J.D.</td>\n",
       "      <td>2020</td>\n",
       "      <td>978</td>\n",
       "      <td>{''}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>[do, she, know, you, call, I, after, hour, whi...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66911</th>\n",
       "      <td>66911</td>\n",
       "      <td>15437</td>\n",
       "      <td>PRETTY</td>\n",
       "      <td>Kennie J.D.</td>\n",
       "      <td>2020</td>\n",
       "      <td>978</td>\n",
       "      <td>{''}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[red, dress, red, everything, black, silk, wha...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66912</th>\n",
       "      <td>66912</td>\n",
       "      <td>15438</td>\n",
       "      <td>Crawling Back</td>\n",
       "      <td>Alex Goot</td>\n",
       "      <td>2013</td>\n",
       "      <td>65</td>\n",
       "      <td>{''}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[I, try, to, leave, you, once, but, I, could, ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66913</th>\n",
       "      <td>66913</td>\n",
       "      <td>15439</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Naive New Beaters</td>\n",
       "      <td>2015</td>\n",
       "      <td>454</td>\n",
       "      <td>{''}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[ride, cadillac, just, like, dr, dre, dre, dre...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66914</th>\n",
       "      <td>66914</td>\n",
       "      <td>15439</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Naive New Beaters</td>\n",
       "      <td>2015</td>\n",
       "      <td>454</td>\n",
       "      <td>{''}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[think, I, be, start, know, what, u, guy, talk...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66915 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                   title             artist  year  \\\n",
       "0               0      0  Something in the Water      Pokey LaFarge  2015   \n",
       "1               1      0  Something in the Water      Pokey LaFarge  2015   \n",
       "2               2      0  Something in the Water      Pokey LaFarge  2015   \n",
       "3               3      0  Something in the Water      Pokey LaFarge  2015   \n",
       "4               4      0  Something in the Water      Pokey LaFarge  2015   \n",
       "...           ...    ...                     ...                ...   ...   \n",
       "66910       66910  15437                  PRETTY        Kennie J.D.  2020   \n",
       "66911       66911  15437                  PRETTY        Kennie J.D.  2020   \n",
       "66912       66912  15438           Crawling Back          Alex Goot  2013   \n",
       "66913       66913  15439                  Jersey  Naive New Beaters  2015   \n",
       "66914       66914  15439                  Jersey  Naive New Beaters  2015   \n",
       "\n",
       "       views features  is_country  is_pop  is_rap  is_rb  is_rock  \\\n",
       "0      10902     {''}        True   False   False  False    False   \n",
       "1      10902     {''}        True   False   False  False    False   \n",
       "2      10902     {''}        True   False   False  False    False   \n",
       "3      10902     {''}        True   False   False  False    False   \n",
       "4      10902     {''}        True   False   False  False    False   \n",
       "...      ...      ...         ...     ...     ...    ...      ...   \n",
       "66910    978     {''}       False    True   False  False    False   \n",
       "66911    978     {''}       False    True   False  False    False   \n",
       "66912     65     {''}       False    True   False  False    False   \n",
       "66913    454     {''}       False    True   False  False    False   \n",
       "66914    454     {''}       False    True   False  False    False   \n",
       "\n",
       "       stanza_number  is_chorus  \\\n",
       "0                  0      False   \n",
       "1                  1       True   \n",
       "2                  2      False   \n",
       "3                  4      False   \n",
       "4                  5       True   \n",
       "...              ...        ...   \n",
       "66910              4       True   \n",
       "66911              5      False   \n",
       "66912              0      False   \n",
       "66913              0      False   \n",
       "66914              1      False   \n",
       "\n",
       "                                      lemmatized_stanzas         label  \n",
       "0      [she, get, a, broke, down, el, camino, in, the...         anger  \n",
       "1      [something, in, the, water, something, in, the...         anger  \n",
       "2      [she, do, her, makeup, and, hair, to, cook, fr...  anticipation  \n",
       "3      [my, hoosi, girl, be, so, fine, shake, the, wa...          fear  \n",
       "4      [something, in, the, water, something, in, the...          fear  \n",
       "...                                                  ...           ...  \n",
       "66910  [do, she, know, you, call, I, after, hour, whi...          fear  \n",
       "66911  [red, dress, red, everything, black, silk, wha...           joy  \n",
       "66912  [I, try, to, leave, you, once, but, I, could, ...  anticipation  \n",
       "66913  [ride, cadillac, just, like, dr, dre, dre, dre...           joy  \n",
       "66914  [think, I, be, start, know, what, u, guy, talk...      surprise  \n",
       "\n",
       "[66915 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['lemmatized_stanzas'] = df['lemmatized_stanzas'].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Convert token lists back into space-separated strings\n",
    "# (needed for vectorizer)\n",
    "# texts_str = df['lemmatized_stanzas'].apply(\n",
    "#     lambda tokens: \" \".join(tokens)\n",
    "# )\n",
    "# print(texts_str)\n",
    "df['text_str'] = df['lemmatized_stanzas'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[\n",
    "        'text_str', 'stanza_number', 'is_country',\n",
    "        'is_pop', 'is_rap', 'is_rb', 'is_rock', 'is_chorus'\n",
    "    ]],\n",
    "    df['label'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "def convert_bool_to_int(x):\n",
    "    return x.astype(int)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'text_str'),\n",
    "        ('scaler', StandardScaler(), ['stanza_number']),\n",
    "        (\n",
    "            'bools', FunctionTransformer(\n",
    "                convert_bool_to_int, validate=False\n",
    "            ), [\n",
    "                'is_country', 'is_pop', 'is_rap',\n",
    "                'is_rb', 'is_rock', 'is_chorus'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_param_distributions = {\n",
    "    'preprocessor__text__max_features': [500, 1000, 5000, None],  # Max features for TF-IDF\n",
    "    'preprocessor__text__ngram_range': [(1, 1), (1, 2)],          # Unigrams or bigrams\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],              # Number of trees\n",
    "    'classifier__max_depth': [None, 10, 20, 30],                  # Tree depth\n",
    "    'classifier__min_samples_split': [2, 5, 10],                  # Min samples per split\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],                    # Min samples per leaf\n",
    "    'classifier__bootstrap': [True, False],                       # Bootstrap sampling\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator= rf_pipeline,\n",
    "    param_distributions= rf_param_distributions,\n",
    "    n_iter=20,                                  # Number of random combinations to try\n",
    "    cv=5,                                       # 5-fold cross-validation\n",
    "    scoring='accuracy',                         # Metric to optimize\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                                   # Use all available cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=  37.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=  37.4s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=  37.6s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=  37.7s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=  37.7s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  38.8s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  38.8s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  39.1s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 1.4min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 1.4min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 1.4min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  14.9s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  15.0s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  15.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  15.1s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=   5.8s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=   5.8s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=   5.9s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  14.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=   5.8s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=   5.9s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  38.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  38.5s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 1.4min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 1.4min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  22.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  22.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  22.1s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  22.7s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  22.7s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time= 5.3min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time= 5.3min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time= 5.3min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time= 5.3min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time= 5.3min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  13.4s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  13.1s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  13.1s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  12.7s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  12.6s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  16.1s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  16.2s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  16.3s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  15.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time=  15.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  46.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  47.0s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  45.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  46.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=30, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=  46.5s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 7.2min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 7.2min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 7.1min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time= 1.1min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=  28.2s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=  28.1s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time= 1.2min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time= 1.1min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time= 1.2min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=  27.2s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=  27.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 1); total time= 1.1min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=  27.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time=  26.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time=  26.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time=  26.7s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time=  26.6s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  24.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=20, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 2); total time=  26.6s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  23.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  23.9s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  23.8s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=10, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  23.5s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 7.1min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time= 7.2min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time= 2.8min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time= 2.7min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time= 2.7min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time= 2.7min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time= 2.1min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time= 2.1min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=30, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=300, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time= 2.7min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time= 2.1min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time= 2.1min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  19.4s\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time= 2.1min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  19.2s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  19.1s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  19.4s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=10, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=  19.3s\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time= 9.6min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time= 9.6min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time= 9.6min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time= 7.6min\n",
      "[CV] END classifier__bootstrap=True, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time= 7.5min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=58.7min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=58.7min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=58.8min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=58.8min\n",
      "[CV] END classifier__bootstrap=False, classifier__max_depth=None, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=300, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=58.7min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                                               TfidfVectorizer(),\n",
       "                                                                               &#x27;text_str&#x27;),\n",
       "                                                                              (&#x27;scaler&#x27;,\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               [&#x27;stanza_number&#x27;]),\n",
       "                                                                              (&#x27;bools&#x27;,\n",
       "                                                                               FunctionTransformer(func=&lt;function convert_bool_to_int at 0x141206e80&gt;),\n",
       "                                                                               [&#x27;is_country&#x27;,\n",
       "                                                                                &#x27;is_pop&#x27;,\n",
       "                                                                                &#x27;is_rap&#x27;,\n",
       "                                                                                &#x27;is_rb&#x27;,\n",
       "                                                                                &#x27;is_rock&#x27;,\n",
       "                                                                                &#x27;is_chorus&#x27;])])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              RandomFor...\n",
       "                   param_distributions={&#x27;classifier__bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;classifier__max_depth&#x27;: [None, 10, 20,\n",
       "                                                                  30],\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                         4],\n",
       "                                        &#x27;classifier__min_samples_split&#x27;: [2, 5,\n",
       "                                                                          10],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     200, 300],\n",
       "                                        &#x27;preprocessor__text__max_features&#x27;: [500,\n",
       "                                                                             1000,\n",
       "                                                                             5000,\n",
       "                                                                             None],\n",
       "                                        &#x27;preprocessor__text__ngram_range&#x27;: [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                                               TfidfVectorizer(),\n",
       "                                                                               &#x27;text_str&#x27;),\n",
       "                                                                              (&#x27;scaler&#x27;,\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               [&#x27;stanza_number&#x27;]),\n",
       "                                                                              (&#x27;bools&#x27;,\n",
       "                                                                               FunctionTransformer(func=&lt;function convert_bool_to_int at 0x141206e80&gt;),\n",
       "                                                                               [&#x27;is_country&#x27;,\n",
       "                                                                                &#x27;is_pop&#x27;,\n",
       "                                                                                &#x27;is_rap&#x27;,\n",
       "                                                                                &#x27;is_rb&#x27;,\n",
       "                                                                                &#x27;is_rock&#x27;,\n",
       "                                                                                &#x27;is_chorus&#x27;])])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              RandomFor...\n",
       "                   param_distributions={&#x27;classifier__bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;classifier__max_depth&#x27;: [None, 10, 20,\n",
       "                                                                  30],\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                         4],\n",
       "                                        &#x27;classifier__min_samples_split&#x27;: [2, 5,\n",
       "                                                                          10],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     200, 300],\n",
       "                                        &#x27;preprocessor__text__max_features&#x27;: [500,\n",
       "                                                                             1000,\n",
       "                                                                             5000,\n",
       "                                                                             None],\n",
       "                                        &#x27;preprocessor__text__ngram_range&#x27;: [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(),\n",
       "                                                  &#x27;text_str&#x27;),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;stanza_number&#x27;]),\n",
       "                                                 (&#x27;bools&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function convert_bool_to_int at 0x141206e80&gt;),\n",
       "                                                  [&#x27;is_country&#x27;, &#x27;is_pop&#x27;,\n",
       "                                                   &#x27;is_rap&#x27;, &#x27;is_rb&#x27;, &#x27;is_rock&#x27;,\n",
       "                                                   &#x27;is_chorus&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(bootstrap=False, min_samples_split=10,\n",
       "                                        n_estimators=200, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(), &#x27;text_str&#x27;),\n",
       "                                (&#x27;scaler&#x27;, StandardScaler(), [&#x27;stanza_number&#x27;]),\n",
       "                                (&#x27;bools&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function convert_bool_to_int at 0x141206e80&gt;),\n",
       "                                 [&#x27;is_country&#x27;, &#x27;is_pop&#x27;, &#x27;is_rap&#x27;, &#x27;is_rb&#x27;,\n",
       "                                  &#x27;is_rock&#x27;, &#x27;is_chorus&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">text</label><div class=\"sk-toggleable__content fitted\"><pre>text_str</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">scaler</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;stanza_number&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">bools</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;is_country&#x27;, &#x27;is_pop&#x27;, &#x27;is_rap&#x27;, &#x27;is_rb&#x27;, &#x27;is_rock&#x27;, &#x27;is_chorus&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function convert_bool_to_int at 0x141206e80&gt;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(bootstrap=False, min_samples_split=10, n_estimators=200,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              ColumnTransformer(transformers=[('text',\n",
       "                                                                               TfidfVectorizer(),\n",
       "                                                                               'text_str'),\n",
       "                                                                              ('scaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['stanza_number']),\n",
       "                                                                              ('bools',\n",
       "                                                                               FunctionTransformer(func=<function convert_bool_to_int at 0x141206e80>),\n",
       "                                                                               ['is_country',\n",
       "                                                                                'is_pop',\n",
       "                                                                                'is_rap',\n",
       "                                                                                'is_rb',\n",
       "                                                                                'is_rock',\n",
       "                                                                                'is_chorus'])])),\n",
       "                                             ('classifier',\n",
       "                                              RandomFor...\n",
       "                   param_distributions={'classifier__bootstrap': [True, False],\n",
       "                                        'classifier__max_depth': [None, 10, 20,\n",
       "                                                                  30],\n",
       "                                        'classifier__min_samples_leaf': [1, 2,\n",
       "                                                                         4],\n",
       "                                        'classifier__min_samples_split': [2, 5,\n",
       "                                                                          10],\n",
       "                                        'classifier__n_estimators': [50, 100,\n",
       "                                                                     200, 300],\n",
       "                                        'preprocessor__text__max_features': [500,\n",
       "                                                                             1000,\n",
       "                                                                             5000,\n",
       "                                                                             None],\n",
       "                                        'preprocessor__text__ngram_range': [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit RandomizedSearchCV to the data\n",
    "random_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'preprocessor__text__ngram_range': (1, 1), 'preprocessor__text__max_features': None, 'classifier__n_estimators': 200, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': None, 'classifier__bootstrap': False}\n",
      "Best Cross-Validation Accuracy: 0.3541204099060632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.43      0.68      0.53      4012\n",
      "anticipation       0.52      0.09      0.16      1820\n",
      "     disgust       0.47      0.07      0.12      1234\n",
      "        fear       0.31      0.40      0.35      3615\n",
      "         joy       0.31      0.55      0.39      3126\n",
      "     sadness       0.48      0.18      0.27      2424\n",
      "    surprise       0.45      0.08      0.14      1295\n",
      "       trust       0.35      0.24      0.29      2549\n",
      "\n",
      "    accuracy                           0.37     20075\n",
      "   macro avg       0.41      0.29      0.28     20075\n",
      "weighted avg       0.40      0.37      0.33     20075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and cross-validation accuracy\n",
    "print(f\"Best Parameters: {random_search_rf.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {random_search_rf.best_score_}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_search_rf.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brunobarbieri/Library/CloudStorage/OneDrive-UniversityofPisa/TA_Project/models/RF_04-12-2024_23-45-10.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saves the model\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "model_path = '/Users/brunobarbieri/Library/CloudStorage/OneDrive-UniversityofPisa/TA_Project/models/'\n",
    "\n",
    "import joblib\n",
    "joblib.dump(\n",
    "    random_search_rf.best_estimator_,\n",
    "    model_path + 'RF_' + datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") + '.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarizzazione delle etichette per il supporto multi-classe\n",
    "classes = df['label'].unique()\n",
    "y_train_bin = label_binarize(y_train, classes=classes)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Calcolo delle probabilitÃ  del modello\n",
    "# (Nota: LinearSVC non fornisce probabilitÃ , ma possiamo usare la decision_function)\n",
    "y_score = random_search_rf.decision_function(X_test)\n",
    "\n",
    "# Plot delle ROC curve per ogni classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, class_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"Class {class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "# Aggiungi la linea di riferimento (y=x)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Configura il grafico\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Random\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "svm_param_distributions = {\n",
    "    'preprocessor__text__max_features': [500, 1000, 5000, None],\n",
    "    'preprocessor__text__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'classifier__degree': [2, 3, 4],\n",
    "    'classifier__gamma': ['scale', 'auto'],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "    estimator= svm_pipeline,\n",
    "    param_distributions= svm_param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(51187) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(51188) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(51189) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__class_weight=None, classifier__degree=3, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=24.8min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=None, classifier__degree=3, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=24.9min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=None, classifier__degree=3, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=25.3min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=None, classifier__degree=3, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=24.4min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=None, classifier__degree=3, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=24.4min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=28.3min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=28.2min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=28.2min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=28.2min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=28.1min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=scale, classifier__kernel=rbf, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time=40.1min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=scale, classifier__kernel=rbf, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time=40.5min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=scale, classifier__kernel=rbf, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time=40.1min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=147.0min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=147.3min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=149.2min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=151.2min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=152.3min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=scale, classifier__kernel=rbf, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time=39.9min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=scale, classifier__kernel=rbf, preprocessor__text__max_features=500, preprocessor__text__ngram_range=(1, 1); total time=39.5min\n",
      "[CV] END classifier__C=10, classifier__class_weight=None, classifier__degree=4, classifier__gamma=scale, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=12.7min\n",
      "[CV] END classifier__C=10, classifier__class_weight=None, classifier__degree=4, classifier__gamma=scale, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=12.6min\n",
      "[CV] END classifier__C=10, classifier__class_weight=None, classifier__degree=4, classifier__gamma=scale, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=12.9min\n",
      "[CV] END classifier__C=10, classifier__class_weight=None, classifier__degree=4, classifier__gamma=scale, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=12.5min\n",
      "[CV] END classifier__C=10, classifier__class_weight=None, classifier__degree=4, classifier__gamma=scale, classifier__kernel=sigmoid, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=12.9min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=33.0min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=32.9min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=32.9min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=33.0min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=32.8min\n",
      "[CV] END classifier__C=100, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=109.6min\n",
      "[CV] END classifier__C=100, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=113.5min\n",
      "[CV] END classifier__C=100, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=116.2min\n",
      "[CV] END classifier__C=100, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=116.5min\n",
      "[CV] END classifier__C=100, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=115.7min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=40.1min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=39.1min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=38.9min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=auto, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=25.8min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=39.4min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=2, classifier__gamma=scale, classifier__kernel=linear, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 1); total time=39.2min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=auto, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=25.8min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=auto, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=25.7min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=auto, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=25.7min\n",
      "[CV] END classifier__C=100, classifier__class_weight=None, classifier__degree=2, classifier__gamma=auto, classifier__kernel=poly, preprocessor__text__max_features=5000, preprocessor__text__ngram_range=(1, 2); total time=25.6min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=43.8min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=43.9min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=43.7min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=21.7min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=43.4min\n",
      "[CV] END classifier__C=10, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=sigmoid, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 2); total time=43.4min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=22.0min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=21.9min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=21.9min\n",
      "[CV] END classifier__C=1, classifier__class_weight=balanced, classifier__degree=3, classifier__gamma=auto, classifier__kernel=linear, preprocessor__text__max_features=None, preprocessor__text__ngram_range=(1, 1); total time=22.5min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=27.8min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=27.8min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=27.5min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=27.8min\n",
      "[CV] END classifier__C=0.1, classifier__class_weight=balanced, classifier__degree=4, classifier__gamma=auto, classifier__kernel=rbf, preprocessor__text__max_features=1000, preprocessor__text__ngram_range=(1, 2); total time=27.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit RandomizedSearchCV to the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrandom_search_svm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit RandomizedSearchCV to the data\n",
    "random_search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'preprocessor__text__ngram_range': (1, 1), 'preprocessor__text__max_features': None, 'classifier__n_estimators': 200, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': None, 'classifier__bootstrap': False}\n",
      "Best Cross-Validation Accuracy: 0.4204524154195076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.42      0.93      0.58      2979\n",
      "anticipation       0.44      0.19      0.26       921\n",
      "     disgust       0.37      0.06      0.11       524\n",
      "        fear       0.51      0.25      0.33      1667\n",
      "         joy       0.48      0.11      0.18       445\n",
      "     sadness       0.42      0.22      0.29      1110\n",
      "    surprise       0.48      0.10      0.16       494\n",
      "       trust       0.44      0.08      0.13       623\n",
      "\n",
      "    accuracy                           0.43      8763\n",
      "   macro avg       0.45      0.24      0.25      8763\n",
      "weighted avg       0.44      0.43      0.36      8763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and cross-validation accuracy\n",
    "print(f\"Best Parameters: {random_search_svm.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {random_search_svm.best_score_}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_search_svm.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brunobarbieri/Library/CloudStorage/OneDrive-UniversityofPisa/TA_Project/models/best_svm_pipeline.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(\n",
    "    random_search_rf.best_estimator_,\n",
    "    model_path + 'SVM_' + datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") + '.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizzazione delle etichette per il supporto multi-classe\n",
    "classes = df['label'].unique()\n",
    "y_train_bin = label_binarize(y_train, classes=classes)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Calcolo delle probabilitÃ  del modello\n",
    "# (Nota: LinearSVC non fornisce probabilitÃ , ma possiamo usare la decision_function)\n",
    "y_score = random_search_svm.decision_function(X_test)\n",
    "\n",
    "# Plot delle ROC curve per ogni classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, class_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"Class {class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "# Aggiungi la linea di riferimento (y=x)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Configura il grafico\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Multi-Class SVM (One-vs-Rest)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
